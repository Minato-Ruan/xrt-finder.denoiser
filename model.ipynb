{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Import Image Data\n",
    "> Save numpy format image to pickle file(./tmp/image_data.pkl)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pic_path = \"./data\"\n",
    "label_list = glob.glob(os.path.join(pic_path, '*'))\n",
    "\n",
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# image_data = pd.DataFrame(columns=[\"image\", \"label\"])\n",
    "#\n",
    "# for path, label in zip(label_list, label_list):\n",
    "#     pic_arr = [np.load(os.path.join(path, path_itm)) for path_itm in os.listdir(path) if path_itm[-3:]==\"npy\"]\n",
    "#     tmp_data = pd.DataFrame({\n",
    "#         \"image\": pic_arr\n",
    "#     })\n",
    "#     tmp_data[\"label\"] = label.split(\"/\")[-1]\n",
    "#\n",
    "#     image_data = image_data.append(tmp_data)\n",
    "#\n",
    "# image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# image_data.to_pickle('tmp/image_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "image_data = pd.read_pickle(\"tmp/image_data.pkl\")\n",
    "image_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Show Sample Image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "not_cataloged_sample = image_data[\n",
    "    image_data[\"label\"]==\"No_Catalogue\"].sample(n=9)[\"image\"]\n",
    "\n",
    "for index, pic in enumerate(not_cataloged_sample):\n",
    "    plt.subplot(3, 3, index+1)\n",
    "    plt.imshow(pic)\n",
    "    plt.title(\"Not_Cataloged\")\n",
    "    plt.colorbar()\n",
    "    plt.grid(False)\n",
    "\n",
    "plt.subplots_adjust(wspace=0, hspace=0.8)\n",
    "# plt.savefig(f\"./pic/{\"Not_Cataloged\"}.png\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def fft_shift(img):\n",
    "    fft_pic = np.fft.fft2(img)\n",
    "    # fft_pic_log = np.log(np.abs(fft_pic))\n",
    "    fft_pic_log =  np.fft.fftshift(np.abs(fft_pic))\n",
    "\n",
    "    return fft_pic_log\n",
    "\n",
    "\n",
    "ffted_data = image_data.copy()\n",
    "ffted_data[\"image\"] = ffted_data[\"image\"].apply(fft_shift)\n",
    "\n",
    "ffted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "min_number = ffted_data.label.value_counts().min()\n",
    "\n",
    "ffted_data = pd.concat([ffted_data[ffted_data[\"label\"] == \"No_Catalogue\"].sample(min_number),\n",
    "                        ffted_data[ffted_data[\"label\"] == \"Catalogued\"].sample(min_number)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ffted_data.loc[:, \"number_l\"] = ffted_data.loc[:, \"label\"].apply(lambda x: x==\"Catalogued\")\n",
    "ffted_data = ffted_data.astype({\"number_l\": int})\n",
    "ffted_data.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ffted = ffted_data[\n",
    "    ffted_data[\"label\"]==\"Catalogued\"].sample(n=9)[\"image\"]\n",
    "\n",
    "for index, pic in enumerate(ffted):\n",
    "    plt.subplot(3,3,index+1)\n",
    "    plt.imshow(pic, cmap = 'gray')\n",
    "    plt.title(\"Catalogued_FFT\")\n",
    "    plt.colorbar()\n",
    "    plt.grid(False)\n",
    "\n",
    "plt.subplots_adjust(wspace=0, hspace=0.8)\n",
    "# plt.savefig(f\"./pic/{\"Catalogued\"}.png\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Adapt Number of Image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "min_number = image_data.label.value_counts().min()\n",
    "\n",
    "fixed_data = pd.concat([image_data[image_data[\"label\"] == \"No_Catalogue\"].sample(min_number),\n",
    "                       image_data[image_data[\"label\"] == \"Catalogued\"].sample(min_number)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fixed_data.loc[:, \"number_l\"] = fixed_data.loc[:, \"label\"].apply(lambda x: x==\"Catalogued\")\n",
    "fixed_data = fixed_data.astype({\"number_l\": int})\n",
    "fixed_data.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fixed_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras.layers as layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "SHUFFLE_BUFFER_SIZE = 100\n",
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "total_train_set = fixed_data.copy()\n",
    "del total_train_set[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "total_train_set = total_train_set.sample(frac=1)\n",
    "\n",
    "tmp_array = []\n",
    "total_train_set[\"image\"].apply(tmp_array.append)\n",
    "tmp_array = np.array(tmp_array, dtype=int)\n",
    "tmp_array = np.stack((tmp_array,), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "total_dataset = tf.data.Dataset.from_tensor_slices((tmp_array, total_train_set[\"number_l\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### LeNet Model(No FFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ada_layer = tf.keras.layers.experimental.preprocessing.Normalization()\n",
    "ada_layer.adapt(tmp_array)\n",
    "\n",
    "le_net_model = tf.keras.Sequential([\n",
    "    layer.Input((32, 32, 1)),\n",
    "    ada_layer,\n",
    "    layer.ZeroPadding2D((1, 1)),\n",
    "    layer.Conv2D(6, (5, 5), strides=(1, 1), padding='valid', name='conv1'),\n",
    "    layer.Activation('relu'),\n",
    "    layer.MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "    layer.Conv2D(6, (5, 5), strides=(1, 1), padding='valid', name='conv2'),\n",
    "    layer.Activation('relu'),\n",
    "    layer.MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "    layer.Flatten(),\n",
    "    layer.Dense(24, activation='relu', name='fc1'),\n",
    "    layer.Dense(13, activation='relu', name='fc2'),\n",
    "    layer.Dropout(0.2),\n",
    "    layer.Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "le_net_model.compile(optimizer=tf.keras.optimizers.RMSprop(),\n",
    "                     loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                     metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "le_net_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Simple NN(No FFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ada_layer = tf.keras.layers.experimental.preprocessing.Normalization()\n",
    "ada_layer.adapt(tmp_array)\n",
    "\n",
    "simple_nn_model = tf.keras.Sequential([\n",
    "    layer.Input((32, 32, 1)),\n",
    "    ada_layer,\n",
    "    layer.Flatten(),\n",
    "    layer.Dense(24, activation='relu', name='fc1'),\n",
    "    layer.Dense(13, activation='relu', name='fc2'),\n",
    "    layer.Dropout(0.2),\n",
    "    layer.Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "simple_nn_model.compile(optimizer=tf.keras.optimizers.RMSprop(),\n",
    "                     loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                     metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "simple_nn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### LeNet (FFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fft_total_set = ffted_data.copy()\n",
    "fft_total_set[\"number_l\"] = fft_total_set[\"label\"].apply(lambda x: x==\"Catalogued\")\n",
    "del fft_total_set[\"label\"]\n",
    "\n",
    "fft_total_set = fft_total_set.astype({\"number_l\": int}).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp_array = []\n",
    "fft_total_set[\"image\"].apply(tmp_array.append)\n",
    "tmp_array = np.array(tmp_array, dtype=float)\n",
    "tmp_array = np.stack((tmp_array,), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fft_total_dataset = tf.data.Dataset.from_tensor_slices((tmp_array, fft_total_set[\"number_l\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fft_ada_layer = tf.keras.layers.experimental.preprocessing.Normalization()\n",
    "fft_ada_layer.adapt(tmp_array)\n",
    "\n",
    "fft_le_net_model = tf.keras.Sequential([\n",
    "    layer.Input((32, 32, 1)),\n",
    "    fft_ada_layer,\n",
    "    layer.ZeroPadding2D((1, 1)),\n",
    "    layer.Conv2D(6, (5, 5), strides=(1, 1), padding='valid', name='conv1'),\n",
    "    layer.Activation('relu'),\n",
    "    layer.MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "    layer.Conv2D(6, (5, 5), strides=(1, 1), padding='valid', name='conv2'),\n",
    "    layer.Activation('relu'),\n",
    "    layer.MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "    layer.Flatten(),\n",
    "    layer.Dense(24, activation='relu', name='fc1'),\n",
    "    layer.Dense(13, activation='relu', name='fc2'),\n",
    "    layer.Dropout(0.2),\n",
    "    layer.Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fft_le_net_model.compile(optimizer=tf.keras.optimizers.RMSprop(),\n",
    "                         loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                         metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    "                         run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fft_le_net_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Simple NN (with FFT) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fft_ada_layer = tf.keras.layers.experimental.preprocessing.Normalization()\n",
    "fft_ada_layer.adapt(tmp_array)\n",
    "\n",
    "fft_simple_nn_model = tf.keras.Sequential([\n",
    "    layer.Input((32, 32, 1)),\n",
    "    fft_ada_layer,\n",
    "    layer.Flatten(),\n",
    "    layer.Dense(24, activation='relu', name='fc1'),\n",
    "    layer.Dense(13, activation='relu', name='fc2'),\n",
    "    layer.Dropout(0.2),\n",
    "    layer.Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fft_simple_nn_model.compile(optimizer=tf.keras.optimizers.RMSprop(),\n",
    "                         loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                         metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fft_simple_nn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### ResNet50 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "resnet50_model = tf.keras.applications.ResNet50(weights=None,\n",
    "                                                include_top=False,\n",
    "                                                input_shape=(32,32,3),\n",
    "                                                pooling=\"avg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "resnet50_model.compile(optimizer=tf.keras.optimizers.RMSprop(),\n",
    "                        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ffted_data_random = ffted_data.sample(frac=1)\n",
    "fixed_data_random = fixed_data.sample(frac=1)\n",
    "fixed_data_random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Data without FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_sample(df: pd.DataFrame, number: int = 1, rgb: str = \"1d\"):\n",
    "    n1_df = df[df[\"number_l\"]==1].sample(frac=1/number)\n",
    "    n0_df = df[df[\"number_l\"]==0].sample(frac=1/number)\n",
    "    print(str(min(len(n1_df), len(n0_df))))\n",
    "    new_df = pd.concat((n1_df, n0_df))\n",
    "    new_df = new_df.sample(frac=1)\n",
    "\n",
    "\n",
    "    values = []\n",
    "    new_df[\"image\"].apply(values.append)\n",
    "    values = np.array(values, dtype=float)\n",
    "    if rgb == \"1d\":\n",
    "        values = np.stack((values,), axis=-1)\n",
    "    elif rgb==\"3d\":\n",
    "        values = np.stack((values,)*3, axis=-1)\n",
    "\n",
    "    labels= np.array(new_df[\"number_l\"].copy())\n",
    "\n",
    "    train_set_val, test_set_val, *_ = np.array_split(values, 2)\n",
    "    train_set_labels, test_set_labels, *_ = np.array_split(labels, 2)\n",
    "\n",
    "    print(\" train_dataset shape = \" + str(train_set_val.shape[0]) +\n",
    "          \"\\n train_set_labels shape = \" + str(train_set_labels.shape[0]) +\n",
    "          \"\\n test_set_val shape = \" + str(test_set_val.shape[0]) +\n",
    "          \"\\n test_set_labels shape = \" + str(test_set_labels.shape[0]))\n",
    "\n",
    "    print(\"count[0]: \" + str(np.count_nonzero(train_set_labels == 0)) +\n",
    "          \"\\n count[1]: \" + str(np.count_nonzero(train_set_labels == 1)))\n",
    "\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((train_set_val, train_set_labels))\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((test_set_val, test_set_labels))\n",
    "\n",
    "    train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "    test_dataset = test_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "    return train_dataset, test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset_max_1d, test_dataset_max_1d = get_sample(fixed_data, 2)\n",
    "len(train_dataset_max_1d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Data with FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fft_random_values = []\n",
    "ffted_data_random[\"image\"].apply(fft_random_values.append)\n",
    "fft_random_values = np.array(fft_random_values, dtype=float)\n",
    "fft_random_values_1d = np.stack((fft_random_values,), axis=-1)\n",
    "fft_random_values_3d = np.stack((fft_random_values,)*3, axis=-1)\n",
    "fft_random_values_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ffted_data_random.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fft_random_lables = np.array(ffted_data_random[\"number_l\"].copy())\n",
    "fft_random_lables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### LeNet (without FFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = get_sample(fixed_data_random)\n",
    "\n",
    "fixed_data_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "result = le_net_model.fit(train_dataset, epochs=EPOCHS,\n",
    "                          validation_data=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "result.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "le_net_result_dict = {\"max\": result}\n",
    "for times in range(1,10):\n",
    "    train_dataset, test_dataset = get_sample(fixed_data_random, times + 1)\n",
    "\n",
    "    result = le_net_model.fit(train_dataset, epochs=EPOCHS,\n",
    "                              validation_data=test_dataset)\n",
    "\n",
    "    le_net_result_dict[str(times + 1)] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def save_results(result):\n",
    "    result_dict = {}\n",
    "    for name in result:\n",
    "        try:\n",
    "            param_result = {\n",
    "                \"params\": result[name][\"params\"],\n",
    "                \"history\": result[name][\"history\"],\n",
    "                \"epoch\": result[name][\"epoch\"]\n",
    "            }\n",
    "        except TypeError:\n",
    "            param_result = {\n",
    "                \"params\": result[name].params,\n",
    "                \"history\": result[name].history,\n",
    "                \"epoch\": result[name].epoch\n",
    "            }\n",
    "        result_dict[name] = param_result\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "le_net_result = pd.Series(save_results(le_net_result_dict))\n",
    "le_net_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "le_net_result.to_pickle(\"./ml_result_data/lenet_nofft.pkl\")\n",
    "le_net_result.to_csv(\"./ml_result_data/lenet_nofft.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## LeNet with fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = get_sample(ffted_data)\n",
    "result = fft_le_net_model.fit(train_dataset, epochs=EPOCHS,\n",
    "                              validation_data=test_dataset)\n",
    "result.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fft_le_net_result_dict = {\"max\": result}\n",
    "for times in range(1,10):\n",
    "    train_dataset, test_dataset = get_sample(ffted_data, times + 1)\n",
    "\n",
    "    result = fft_le_net_model.fit(train_dataset, epochs=EPOCHS,\n",
    "                                  validation_data=test_dataset)\n",
    "\n",
    "    fft_le_net_result_dict[str(times + 1)] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fft_le_net_result = pd.Series(save_results(fft_le_net_result_dict))\n",
    "fft_le_net_result.to_pickle(\"./ml_result_data/lenet_fft.pkl\")\n",
    "fft_le_net_result.to_csv(\"./ml_result_data/lenet_fft.csv\")\n",
    "\n",
    "fft_le_net_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### NN without fft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = get_sample(fixed_data)\n",
    "result = simple_nn_model.fit(train_dataset, epochs=EPOCHS,\n",
    "                             validation_data=test_dataset)\n",
    "result.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nn_result_dict = {\"max\": result}\n",
    "for times in range(1,10):\n",
    "    train_dataset, test_dataset = get_sample(fixed_data, times + 1)\n",
    "\n",
    "    result = simple_nn_model.fit(train_dataset, epochs=EPOCHS,\n",
    "                                  validation_data=test_dataset)\n",
    "\n",
    "    nn_result_dict[str(times + 1)] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nn_result = pd.Series(save_results(nn_result_dict))\n",
    "nn_result.to_pickle(\"./ml_result_data/nn_nofft.pkl\")\n",
    "nn_result.to_csv(\"./ml_result_data/nn_nofft.csv\")\n",
    "\n",
    "nn_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### NN with fft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = get_sample(ffted_data)\n",
    "result = fft_simple_nn_model.fit(train_dataset, epochs=EPOCHS,\n",
    "                             validation_data=test_dataset)\n",
    "result.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fft_nn_result_dict = {\"max\": result}\n",
    "for times in range(1,10):\n",
    "    train_dataset, test_dataset = get_sample(ffted_data, times + 1)\n",
    "\n",
    "    result = fft_simple_nn_model.fit(train_dataset, epochs=EPOCHS,\n",
    "                                 validation_data=test_dataset)\n",
    "\n",
    "    fft_nn_result_dict[str(times + 1)] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fft_nn_result = pd.Series(save_results(fft_nn_result_dict))\n",
    "fft_nn_result.to_pickle(\"./ml_result_data/nn_fft.pkl\")\n",
    "fft_nn_result.to_csv(\"./ml_result_data/nn_fft.csv\")\n",
    "\n",
    "fft_nn_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# train_dataset, test_dataset = get_sample(ffted_data, rgb=\"3d\")\n",
    "# result = resnet50_model.fit(train_dataset, epochs=EPOCHS,\n",
    "#                             validation_data=test_dataset)\n",
    "# result.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## High epochs test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "result_list = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Simple NN without fft.\n",
    "epochs = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = get_sample(fixed_data)\n",
    "result = simple_nn_model.fit(train_dataset, epochs=400,\n",
    "                             validation_data=test_dataset)\n",
    "result.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "result_list[\"nn_without_fft\"] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Simple NN with fft.\n",
    "epochs = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = get_sample(ffted_data)\n",
    "result = fft_simple_nn_model.fit(train_dataset, epochs=400,validation_data=test_dataset)\n",
    "result.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "result_list[\"nn_with_fft\"] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Simple NN without FFT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### LeNet with fft.\n",
    "epochs = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = get_sample(ffted_data)\n",
    "result = fft_le_net_model.fit(train_dataset, epochs=400,validation_data=test_dataset)\n",
    "result.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "result_list[\"le_net_with_fft\"] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### LeNet without fft.\n",
    "epochs = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = get_sample(fixed_data)\n",
    "result = le_net_model.fit(train_dataset, epochs=400,validation_data=test_dataset)\n",
    "result.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "result_list[\"le_net_without_fft\"] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "result_save = save_results(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd_result = pd.Series(result_save)\n",
    "pd_result.to_pickle(\"high_epochs.pkl\")\n",
    "pd_result.to_csv(\"high_epochs.csv\")\n",
    "pd_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Final Model Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = get_sample(ffted_data)\n",
    "result = fft_le_net_model.fit(train_dataset, epochs=25,validation_data=test_dataset)\n",
    "result.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fft_le_net_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fft_le_net_model.save_weights(\"./model/final-weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fft_le_net_model.save(\"./model/final-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tf.saved_model.save(fft_le_net_model, \"./model/final-model-saver\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Load Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "load_model = tf.keras.models.load_model(\"./model/final-model\")\n",
    "load_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ffted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "load_test_data = ffted_data[\"image\"].to_numpy()\n",
    "load_test_data = list(map(np.array, load_test_data))\n",
    "load_test_data = np.array(load_test_data)\n",
    "\n",
    "load_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_result = ffted_data.copy()\n",
    "test_result_list = load_model.predict(load_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_result[\"predict_sig\"] = list(zip(*test_result_list))[1]\n",
    "test_result[\"predict_noise\"] = list(zip(*test_result_list))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_result[\"predict\"] = test_result[\"predict_sig\"] > test_result[\"predict_noise\"]\n",
    "test_result[\"accuracy\"] = test_result[\"predict\"] == test_result[\"number_l\"]\n",
    "\n",
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_result[\"accuracy\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_result[test_result[\"number_l\"] == 1][\"accuracy\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_result[test_result[\"number_l\"] == 0][\"accuracy\"].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
